{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f0RB4uL8-EG"
   },
   "outputs": [],
   "source": [
    "# Simple AutoEncoder (no convolutional layers)\n",
    "# https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "# https://www.youtube.com/watch?v=wECwVBmPH7w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learned Image Compression (LIC) using autoencoders\n",
    "\n",
    "For reasons of space and speed, we use the mnist dataset, that is composed of 70K images of hand written decimal digits. Notice that with this dataset, all the images have the same shape (28x28 pixels), and are monochromatic (8 bits/pixel). We will use [Keras](https://blog.keras.io/building-autoencoders-in-keras.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using 1 hidden layer and no quantization of the latent space\n",
    "\n",
    "Only the latent layer is hidden.\n",
    "\n",
    "    Input -> Latent -> Output\n",
    "    28x28    32        28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoding example (feeding tf.data.Dataset with NumPy arrays, iterative)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "# Generate the NumPy arrays with the data.\n",
    "DATA_URL = f'https://storage.googleapis.com/tensorflow/tf-keras-datasets/{DATASET}.npz'\n",
    "path = tf.keras.utils.get_file(f'{DATASET}.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['x_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['x_test']\n",
    "\n",
    "# Generate the pipelines.\n",
    "train_DS = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_DS = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Define how to use the datasets, preprocess, etc.\n",
    "\n",
    "def process_x(image, label):\n",
    "    processed_img = tf.reshape(image, (img_height * img_width, 1))\n",
    "    processed_img = tf.cast(processed_img, tf.float32) / 255.\n",
    "    return processed_img, label\n",
    "\n",
    "def process_y(image, label):\n",
    "    # The last layer of the network is a dense layer and TensorFlow imposes 1D.\n",
    "    return image, tf.reshape(image, (img_height * img_width, 1))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_DS = train_DS.map(process_x)\n",
    "train_DS = train_DS.map(process_y)\n",
    "train_DS = train_DS.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_DS = test_DS.map(process_x)\n",
    "test_DS = test_DS.map(process_y)\n",
    "test_DS = test_DS.batch(BATCH_SIZE)\n",
    "\n",
    "# Define the autoencoder.\n",
    "input_layer = keras.Input(\n",
    "    shape=(img_length,))\n",
    "hidden_layer = layers.Dense(\n",
    "    LATENT_SPACE_LENGTH,\n",
    "    activation=\"relu\")(input_layer)\n",
    "output_layer = layers.Dense(\n",
    "    img_length,\n",
    "    activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "autoencoder = keras.Model(\n",
    "    input_layer,\n",
    "    output_layer)\n",
    "\n",
    "# To see the latents (content of the hidden layer), we define a new \"model\" with only the encoder.\n",
    "encoder = keras.Model(\n",
    "    input_layer,\n",
    "    hidden_layer)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train.\n",
    "EPOCHS = 1\n",
    "ITERATIONS = 5\n",
    "plt.gray()\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    autoencoder.fit(\n",
    "        train_DS,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_DS)\n",
    "\n",
    "    # Show the learning.\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    n = len(train_DS)\n",
    "    if n > 32:\n",
    "        n = 32\n",
    "\n",
    "    # Show the originals (using the pipeline).\n",
    "    for images in test_DS.take(1):\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(3, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                #plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # See the latent space (as images).\n",
    "    latent_imgs = encoder.predict(test_DS)\n",
    "    print(\"type latent\", type(latent_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(resize(latent_imgs[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "        plt.axis(\"off\")    \n",
    "    \n",
    "    # See the reconstructions.\n",
    "    reconstructed_imgs = autoencoder.predict(test_DS)\n",
    "    print(type(reconstructed_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.axis(\"off\")    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Quantizing the latent space\n",
    "Add a new custom layer that quantizes the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from scipy.stats import entropy\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "# Generate the NumPy arrays with the data.\n",
    "DATA_URL = f'https://storage.googleapis.com/tensorflow/tf-keras-datasets/{DATASET}.npz'\n",
    "path = tf.keras.utils.get_file(f'{DATASET}.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['x_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['x_test']\n",
    "    \n",
    "# Generate the pipelines.\n",
    "train_DS = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_DS = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Define how to use the datasets, preprocess, etc.\n",
    "\n",
    "def process_x(image, label):\n",
    "    processed_img = tf.reshape(image, (img_height * img_width, 1))\n",
    "    processed_img = tf.cast(processed_img, tf.float32) / 255.\n",
    "    return processed_img, label\n",
    "\n",
    "def process_y(image, label):\n",
    "    # The last layer of the network is a dense layer and TensorFlow imposes 1D.\n",
    "    return image, tf.reshape(image, (img_height * img_width, 1))\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_DS = train_DS.map(process_x)\n",
    "train_DS = train_DS.map(process_y)\n",
    "train_DS = train_DS.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_DS = test_DS.map(process_x)\n",
    "test_DS = test_DS.map(process_y)\n",
    "test_DS = test_DS.batch(BATCH_SIZE)\n",
    "\n",
    "class Quantization_8bits(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(Quantization_8bits, self).__init__(**kwargs)\n",
    "        self.quantized_vals = 0\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        outputs = tf.saturate_cast(tf.round(outputs * 255.), tf.int8)\n",
    "        self.quantized_vals = outputs\n",
    "        outputs = tf.cast(outputs, tf.float32) / 255.0\n",
    "        return outputs\n",
    "    \n",
    "    def get_vals(self):\n",
    "        return self.quantized_vals\n",
    "\n",
    "# Define the autoencoder.\n",
    "input_layer = keras.Input(\n",
    "    shape=(img_length,),\n",
    "    name=\"inputs\")\n",
    "hidden_layer = layers.Dense(\n",
    "    LATENT_SPACE_LENGTH,\n",
    "    activation=\"relu\")(input_layer)\n",
    "quantization_layer = Quantization_8bits(\n",
    "    units=LATENT_SPACE_LENGTH,\n",
    "    name=\"quantization\"\n",
    "    )(hidden_layer)\n",
    "output_layer = layers.Dense(\n",
    "    img_length,\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"outputs\")(quantization_layer)\n",
    "\n",
    "autoencoder = keras.Model(\n",
    "    input_layer,\n",
    "    output_layer)\n",
    "\n",
    "# To see the latents (content of the hidden layer), we define a new \"model\" with only the encoder.\n",
    "encoder = keras.Model(\n",
    "    input_layer,\n",
    "    hidden_layer)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\", run_eagerly=True\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train.\n",
    "EPOCHS = 1\n",
    "ITERATIONS = 1\n",
    "plt.gray()\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    autoencoder.fit(\n",
    "        train_DS,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_DS)\n",
    "\n",
    "    batch_vals = autoencoder.get_layer(\"quantization\").get_vals()\n",
    "    print(\"batch_vals =\", batch_vals)\n",
    "    for j in range(BATCH_SIZE):\n",
    "        try:\n",
    "            vals = batch_vals[j].numpy() + 512\n",
    "            #print(vals)\n",
    "            print(entropy(vals, base=2))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #print(\"2\", autoencoder.get_layer(\"hidden\").variables[1])\n",
    "\n",
    "    # Show the learning.\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    n = len(train_DS)\n",
    "    if n > 32:\n",
    "        n = 32\n",
    "\n",
    "    # Show the originals (using the pipeline).\n",
    "    for images in test_DS.take(1):\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(3, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                #plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # See the latent space (as images).\n",
    "    latent_imgs = encoder.predict(test_DS)\n",
    "    print(\"type latent\", type(latent_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(resize(latent_imgs[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "        plt.axis(\"off\")    \n",
    "    \n",
    "    # See the reconstructions.\n",
    "    reconstructed_imgs = autoencoder.predict(test_DS)\n",
    "    print(type(reconstructed_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.axis(\"off\")    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Quantizing the latent space (only during inferencing)\n",
    "During training, the quantization noise is simulated. During the inference, the latents are quantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from scipy.stats import entropy\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "# Generate the NumPy arrays with the data.\n",
    "DATA_URL = f'https://storage.googleapis.com/tensorflow/tf-keras-datasets/{DATASET}.npz'\n",
    "path = tf.keras.utils.get_file(f'{DATASET}.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['x_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['x_test']\n",
    "    \n",
    "# Generate the pipelines.\n",
    "train_DS = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_DS = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Define how to use the datasets, preprocess, etc.\n",
    "\n",
    "def process_x(image, label):\n",
    "    processed_img = tf.reshape(image, (img_height * img_width, 1))\n",
    "    processed_img = tf.cast(processed_img, tf.float32) / 255.\n",
    "    return processed_img, label\n",
    "\n",
    "def process_y(image, label):\n",
    "    # The last layer of the network is a dense layer and TensorFlow imposes 1D.\n",
    "    return image, tf.reshape(image, (img_height * img_width, 1))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_DS = train_DS.map(process_x)\n",
    "train_DS = train_DS.map(process_y)\n",
    "train_DS = train_DS.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_DS = test_DS.map(process_x)\n",
    "test_DS = test_DS.map(process_y)\n",
    "test_DS = test_DS.batch(BATCH_SIZE)\n",
    "\n",
    "class AddNoise(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        outputs += tf.random.uniform(shape=tf.shape(inputs), minval=-.5, maxval=.5)\n",
    "        return outputs\n",
    "\n",
    "class Quantization_8bits(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.quantized_vals = 0\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        #print(\"a1\", tf.reduce_min(outputs))\n",
    "        #print(\"a2\", tf.reduce_max(outputs))\n",
    "        #outputs = tf.keras.activations.sigmoid(outputs - 0.5)#(outputs + 0.5)\n",
    "        #print(\"d1\", tf.reduce_min(outputs))\n",
    "        #print(\"d2\", tf.reduce_max(outputs))\n",
    "        #output = outputs - 0.5\n",
    "        outputs = tf.saturate_cast(tf.round(outputs * 255.), tf.int16)\n",
    "        self.quantized_vals = outputs\n",
    "        outputs = tf.cast(outputs, tf.float32) / 255.0\n",
    "        return outputs\n",
    "    \n",
    "    def get_vals(self):\n",
    "        return self.quantized_vals\n",
    "\n",
    "# Define the autoencoder.\n",
    "input_layer = keras.Input(\n",
    "    shape=(img_length,),\n",
    "    name=\"inputs\")\n",
    "hidden_layer = layers.Dense(\n",
    "    LATENT_SPACE_LENGTH,\n",
    "    activation=\"relu\")(input_layer)\n",
    "noisy_layer = AddNoise(\n",
    "    units=LATENT_SPACE_LENGTH,\n",
    "    name=\"add_noise\"\n",
    "    )(hidden_layer)\n",
    "output_layer = layers.Dense(\n",
    "    img_length,\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"outputs\")(noisy_layer)\n",
    "\n",
    "autoencoder = keras.Model(\n",
    "    input_layer,\n",
    "    output_layer)\n",
    "\n",
    "# To see the latents (content of the hidden layer), we define a new \"model\" with only the encoder.\n",
    "encoder = keras.Model(\n",
    "    input_layer,\n",
    "    hidden_layer)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\", run_eagerly=True\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "input_layer_2 = keras.Input(\n",
    "    shape=(img_length,),\n",
    "    name=\"inputs_2\")\n",
    "hidden_layer_2 = layers.Dense(\n",
    "    LATENT_SPACE_LENGTH,\n",
    "    activation=\"relu\")(input_layer_2)\n",
    "quantization_layer = Quantization_8bits(\n",
    "    units=LATENT_SPACE_LENGTH,\n",
    "    name=\"quantization\"\n",
    "    )(hidden_layer_2)\n",
    "output_layer_2 = layers.Dense(\n",
    "    img_length,\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"outputs_2\")(quantization_layer)\n",
    "\n",
    "autoencoder_2 = keras.Model(\n",
    "    input_layer_2,\n",
    "    output_layer_2\n",
    ")\n",
    "\n",
    "autoencoder_2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\", run_eagerly=True\n",
    ")\n",
    "\n",
    "autoencoder_2.summary()\n",
    "\n",
    "# Train.\n",
    "EPOCHS = 1\n",
    "ITERATIONS = 1\n",
    "plt.gray()\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    autoencoder.fit(\n",
    "        train_DS,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_DS)\n",
    "\n",
    "    #print(\"2\", autoencoder.get_layer(\"hidden\").variables[1])\n",
    "\n",
    "    # Show the learning.\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    n = len(train_DS)\n",
    "    if n > 32:\n",
    "        n = 32\n",
    "\n",
    "    # Show the originals (using the pipeline).\n",
    "    for images in test_DS.take(1):\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(3, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                #plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # See the latent space (as images).\n",
    "    latent_imgs = encoder.predict(test_DS)\n",
    "    print(\"type latent\", type(latent_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(resize(latent_imgs[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "        plt.axis(\"off\")    \n",
    "    \n",
    "    # See the reconstructions.\n",
    "    autoencoder_2.set_weights(autoencoder.get_weights())\n",
    "    reconstructed_imgs = autoencoder_2.predict(test_DS)\n",
    "    print(type(reconstructed_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    batch_vals = autoencoder_2.get_layer(\"quantization\").get_vals()\n",
    "    print(\"batch_vals =\", batch_vals)\n",
    "    for j in range(BATCH_SIZE):\n",
    "        try:\n",
    "            vals = batch_vals[j].numpy() + 512\n",
    "            #print(vals)\n",
    "            print(entropy(vals, base=2))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. Considering RD tradeoff\n",
    "Optimize the autoencoder for a given $J = R + \\lambda D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "#from scipy.stats import entropy\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "train_DS, test_DS = tfds.load(\n",
    "    DATASET,\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=False,\n",
    ")\n",
    "\n",
    "def encode(latent_dims):\n",
    "  \"\"\"Creates the analysis (encoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Input(\n",
    "            shape=(img_length,), name=\"inputs\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          latent_dims, use_bias=True, activation=\"relu\", name=\"latent\"),\n",
    "  ], name=\"analysis_transform\")\n",
    "\n",
    "def decode():\n",
    "  \"\"\"Creates the synthesis (decoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          img_length, use_bias=True, activation=\"sigmoid\", name=\"outputs\"),\n",
    "  ], name=\"synthesis_transform\")\n",
    "\n",
    "\n",
    "def estimate_rate(x):\n",
    "    def entropy(row):\n",
    "        _, _, count = tf.unique_with_counts(row)\n",
    "        prob = count / tf.reduce_sum(count)\n",
    "        _2 = tf.ones_like(prob)*2\n",
    "        log_2 = tf.cast(tf.math.log(_2), tf.float64)\n",
    "        #print(log_2.dtype, prob.dtype, tf.math.log(prob).dtype)\n",
    "        #return -tf.reduce_sum(prob * tf.math.log(prob))\n",
    "        return -tf.reduce_sum(prob * tf.math.log(prob)/log_2)\n",
    "\n",
    "    #     rev = tf.map_fn(row_entropy, new_f_w_t,dtype=tf.float32)\n",
    "    #entropy_batch = []\n",
    "    #for j in range(len(batch)):\n",
    "    #    entropy_batch.append(entropy(batch, base=2))\n",
    "    #new_f_w_t = tf.histogram_fixed_width_bins(x, value_ranges, nbins)\n",
    "    #rev = tf.map_fn(row_entropy, new_f_w_t,dtype=tf.float32)\n",
    "    value_ranges = [0.0, 32.0]\n",
    "    nbins = 256\n",
    "    #print(\"estimate_rate.max(x)=\",\n",
    "    #      tf.reduce_max(x, axis = 1, keepdims = True),\n",
    "    #      \"estimate_rate.min(x)=\",\n",
    "    #      tf.reduce_min(x, axis = 1, keepdims = True))\n",
    "    histograms = tf.cast(tf.histogram_fixed_width_bins(x, value_ranges, nbins), tf.float32)\n",
    "    entropies = tf.map_fn(fn=entropy, elems=histograms, dtype=tf.float64)\n",
    "    rate = tf.reduce_sum(entropies)\n",
    "    #print(\"----------------___\", histograms.dtype, entropies.dtype, rate.dtype)\n",
    "    \n",
    "    rate /= (tf.cast(tf.size(entropies), tf.float64))\n",
    "    #tf.print(\"rate=\", rate)\n",
    "    return rate\n",
    "\n",
    "class Trainer(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dims):\n",
    "        super().__init__()\n",
    "        self.encode = encode(latent_dims)\n",
    "        self.decode = decode()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Computes rate and distortion losses.\"\"\"\n",
    "        # Ensure inputs are floats in the range (0, 1).\n",
    "        #tf.print(\"x=\", x) # <- produces 0\n",
    "        #print(\"max x\", tf.reduce_max(x))\n",
    "        \n",
    "        x = tf.cast(x, self.compute_dtype) / 255.\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "\n",
    "        # Compute latent space representation y, perturb it and model its entropy,\n",
    "        # then compute the reconstructed pixel-level representation x_hat.\n",
    "        y = self.encode(x)\n",
    "        #print(\"size(y)=\", tf.size(y))\n",
    "        #print(\"len(y)=\", len(y))\n",
    "        #print(\"shape(y)\", tf.shape(y))\n",
    "        #print(\"size(x)=\", tf.size(x))\n",
    "        #tf.print(\"x=\", x)\n",
    "        #tf.print(\"y=\", y)\n",
    "\n",
    "        rate = estimate_rate(y)\n",
    "        x_hat = self.decode(y)\n",
    "        #print(\"Autoencoder.call.max(y)=\", tf.reduce_max(y))\n",
    "        #print(\"Autoencoder.call.max(x)=\", tf.reduce_max(x))\n",
    "        #print(\"Autoencoder.call.max(x_hat)=\", tf.reduce_max(x_hat))\n",
    "\n",
    "        # Average number of bits per MNIST digit.\n",
    "        rate = tf.reduce_mean(rate)\n",
    "\n",
    "        # Mean absolute difference across pixels.\n",
    "        distortion = tf.reduce_mean(abs(x - x_hat))\n",
    "\n",
    "        return dict(rate=rate, distortion=distortion)\n",
    "\n",
    "(example_batch, _), = test_DS.batch(32).take(1)\n",
    "trainer = Trainer(10)\n",
    "example_output = trainer(example_batch)\n",
    "\n",
    "print(\"rate: \", example_output[\"rate\"])\n",
    "print(\"distortion: \", example_output[\"distortion\"])\n",
    "\n",
    "def pass_through_loss(_, x):\n",
    "  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n",
    "  return x\n",
    "\n",
    "def configure_training(lmbda, latent_dims=32):\n",
    "    trainer = Trainer(latent_dims)\n",
    "    trainer.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        # Just pass through rate and distortion as losses/metrics.\n",
    "        loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "        metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "        loss_weights=dict(rate=1., distortion=lmbda),)\n",
    "    return trainer\n",
    "\n",
    "def add_rd_targets(image, label):\n",
    "    # Training is unsupervised, so labels aren't necessary here. However, we\n",
    "    # need to add \"dummy\" targets for rate and distortion.\n",
    "    #tf.print(image) <- produce 0\n",
    "    #tf.print(label) <- produce labels\n",
    "    processed_img = tf.reshape(image, (img_height * img_width, 1))\n",
    "    #processed_img = tf.cast(processed_img, tf.float32) / 255.\n",
    "    #tf.print(processed_img)\n",
    "    return processed_img, dict(rate=0., distortion=0.)\n",
    "\n",
    "def train(lmbda, epochs=5):\n",
    "    trainer = configure_training(lmbda)\n",
    "    #print(\"-----------\")\n",
    "    #tf.print(train_DS.take(16))\n",
    "    #print(\"-----------\")\n",
    "    trainer.fit(\n",
    "        train_DS.map(add_rd_targets).batch(128).prefetch(8),\n",
    "        epochs=epochs,\n",
    "        validation_data=test_DS.map(add_rd_targets).batch(128).cache(),\n",
    "        #validation_data=train_DS.map(add_rd_targets).batch(128).cache(),\n",
    "        validation_freq=1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "trainer = train(lmbda=5000)\n",
    "trainer.summary()\n",
    "\n",
    "class Compressor(tf.keras.Model):\n",
    "    def __init__(self, analysis_transform):\n",
    "        super().__init__()\n",
    "        self.analysis_transform = analysis_transform\n",
    "\n",
    "    def call(self, x):\n",
    "        # Ensure inputs are floats in the range (0, 1).\n",
    "        x = tf.cast(x, self.compute_dtype) / 255.\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        y = self.analysis_transform(x)\n",
    "        #tf.print(y)\n",
    "        #print(\"size(y)=\", tf.size(y))\n",
    "        # Also return the exact information content of each digit.\n",
    "        rate = estimate_rate(y)\n",
    "        rate = tf.reduce_mean(rate)\n",
    "        return y, rate\n",
    "\n",
    "class Decompressor(tf.keras.Model):\n",
    "    def __init__(self, synthesis_transform):\n",
    "        super().__init__()\n",
    "        self.synthesis_transform = synthesis_transform\n",
    "\n",
    "    def call(self, y):\n",
    "        #tf.print(y)\n",
    "        #print(\"Decompressor.call.max(y)\", tf.reduce_max(y)) # Returns > 0\n",
    "        x_hat = self.synthesis_transform(y)\n",
    "        #print(\"Decompressor.call.max(x_hat)\", tf.reduce_max(x_hat))\n",
    "        # Scale and cast back to 8-bit integer.\n",
    "        #tf.print(x_hat)\n",
    "        #print(\"Decompressor.call.x_hat\", tf.reduce_max(x_hat)) # Returns 0\n",
    "        return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n",
    "\n",
    "def make_mnist_codec(trainer, **kwargs):\n",
    "    # The entropy model must be created with `compression=True` and the same\n",
    "    # instance must be shared between compressor and decompressor.\n",
    "    compressor = Compressor(trainer.encode)\n",
    "    decompressor = Decompressor(trainer.decode)\n",
    "    return compressor, decompressor\n",
    "\n",
    "compressor, decompressor = make_mnist_codec(trainer)\n",
    "\n",
    "(originals, _), = test_DS.batch(16).skip(3).take(1)\n",
    "y, entropies = compressor(originals)\n",
    "print(\"shape(y)=\", tf.shape(y), \"max(y)=\", tf.reduce_max(y), \"entropies=\", entropies)\n",
    "reconstructed_imgs = decompressor(y)\n",
    "print(\"shape(recons)=\", tf.shape(reconstructed_imgs), \"max(recons)=\", tf.reduce_max(reconstructed_imgs))\n",
    "n = len(reconstructed_imgs)\n",
    "plt.gray()\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 )\n",
    "    plt.imshow(tf.reshape(originals[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    #tf.print(reconstructed_imgs[i])\n",
    "    plt.imshow(resize(y[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "    #plt.imshow(tf.reshape(reconstructed_imgs[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    #tf.print(reconstructed_imgs[i])\n",
    "    plt.imshow(tf.reshape(reconstructed_imgs[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Adding some convolutional layers\n",
    "Now, the dense ANN learns on shapes, not on pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "#from scipy.stats import entropy\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "train_DS, test_DS = tfds.load(\n",
    "    DATASET,\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=False,\n",
    ")\n",
    "\n",
    "def encode(latent_dims):\n",
    "  \"\"\"Creates the analysis (encoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2D(\n",
    "          50, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(\n",
    "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          latent_dims, use_bias=True, activation=\"relu\", name=\"latent\"),\n",
    "  ], name=\"analysis_transform\")\n",
    "\n",
    "def decode():\n",
    "  \"\"\"Creates the synthesis (decoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          2450, use_bias=True, activation=\"leaky_relu\", name=\"fc_2\"),\n",
    "      tf.keras.layers.Reshape((7, 7, 50)),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          1, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "  ], name=\"synthesis_transform\")\n",
    "\n",
    "def estimate_rate(x):\n",
    "    def entropy(row):\n",
    "        _, _, count = tf.unique_with_counts(row)\n",
    "        prob = count / tf.reduce_sum(count)\n",
    "        _2 = tf.ones_like(prob)*2\n",
    "        log_2 = tf.cast(tf.math.log(_2), tf.float64)\n",
    "        return -tf.reduce_sum(prob * tf.math.log(prob)/log_2)\n",
    "\n",
    "    value_ranges = [0.0, 32.0]\n",
    "    nbins = 256\n",
    "    print(\"estimate_rate.max(x)=\",\n",
    "          tf.reduce_max(x, axis = 1, keepdims = True),\n",
    "          \"estimate_rate.min(x)=\",\n",
    "          tf.reduce_min(x, axis = 1, keepdims = True))\n",
    "    histograms = tf.cast(tf.histogram_fixed_width_bins(x, value_ranges, nbins), tf.float32)\n",
    "    entropies = tf.map_fn(fn=entropy, elems=histograms, dtype=tf.float64)\n",
    "    rate = tf.reduce_sum(entropies)\n",
    "    \n",
    "    rate /= (tf.cast(tf.size(entropies), tf.float64))\n",
    "    return rate\n",
    "\n",
    "class Trainer(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dims):\n",
    "        super().__init__()\n",
    "        self.encode = encode(latent_dims)\n",
    "        self.decode = decode()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Computes rate and distortion losses.\"\"\"\n",
    "        # Ensure inputs are floats in the range (0, 1).\n",
    "        x = tf.cast(x, self.compute_dtype) / 255.\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))\n",
    "\n",
    "        # Compute latent space representation y, perturb it and model its entropy,\n",
    "        # then compute the reconstructed pixel-level representation x_hat.\n",
    "        y = self.encode(x)\n",
    "\n",
    "        rate = estimate_rate(y)\n",
    "        x_hat = self.decode(y)\n",
    "\n",
    "        # Average number of bits per MNIST digit.\n",
    "        rate = tf.reduce_mean(rate)\n",
    "\n",
    "        # Mean absolute difference across pixels.\n",
    "        distortion = tf.reduce_mean(abs(x - x_hat))\n",
    "\n",
    "        return dict(rate=rate, distortion=distortion)\n",
    "\n",
    "(example_batch, _), = test_DS.batch(32).take(1)\n",
    "trainer = Trainer(10)\n",
    "example_output = trainer(example_batch)\n",
    "\n",
    "print(\"rate: \", example_output[\"rate\"])\n",
    "print(\"distortion: \", example_output[\"distortion\"])\n",
    "\n",
    "def pass_through_loss(_, x):\n",
    "  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n",
    "  return x\n",
    "\n",
    "def configure_training(lmbda, latent_dims=32):\n",
    "    trainer = Trainer(latent_dims)\n",
    "    trainer.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        # Just pass through rate and distortion as losses/metrics.\n",
    "        loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "        metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "        loss_weights=dict(rate=1., distortion=lmbda),)\n",
    "    return trainer\n",
    "\n",
    "def add_rd_targets(image, label):\n",
    "    # Training is unsupervised, so labels aren't necessary here. However, we\n",
    "    # need to add \"dummy\" targets for rate and distortion.\n",
    "    processed_img = tf.reshape(image, (img_height * img_width, 1))\n",
    "    #processed_img = tf.cast(processed_img, tf.float32) / 255.\n",
    "    return processed_img, dict(rate=0., distortion=0.)\n",
    "\n",
    "def train(lmbda, epochs=5):\n",
    "    trainer = configure_training(lmbda)\n",
    "    trainer.fit(\n",
    "        train_DS.map(add_rd_targets).batch(128).prefetch(8),\n",
    "        epochs=epochs,\n",
    "        validation_data=test_DS.map(add_rd_targets).batch(128).cache(),\n",
    "        validation_freq=1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "trainer = train(lmbda=500)\n",
    "trainer.summary()\n",
    "\n",
    "class Compressor(tf.keras.Model):\n",
    "    def __init__(self, analysis_transform):\n",
    "        super().__init__()\n",
    "        self.analysis_transform = analysis_transform\n",
    "\n",
    "    def call(self, x):\n",
    "        # Ensure inputs are floats in the range (0, 1).\n",
    "        x = tf.cast(x, self.compute_dtype) / 255.\n",
    "        #x = tf.reshape(x, (-1, 28*28))\n",
    "        y = self.analysis_transform(x)\n",
    "        # Also return the exact information content of each digit.\n",
    "        rate = estimate_rate(y)\n",
    "        rate = tf.reduce_mean(rate)\n",
    "        return y, rate\n",
    "\n",
    "class Decompressor(tf.keras.Model):\n",
    "    def __init__(self, synthesis_transform):\n",
    "        super().__init__()\n",
    "        self.synthesis_transform = synthesis_transform\n",
    "\n",
    "    def call(self, y):\n",
    "        x_hat = self.synthesis_transform(y)\n",
    "        # Scale and cast back to 8-bit integer.\n",
    "        return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n",
    "\n",
    "def make_mnist_codec(trainer, **kwargs):\n",
    "    # The entropy model must be created with `compression=True` and the same\n",
    "    # instance must be shared between compressor and decompressor.\n",
    "    compressor = Compressor(trainer.encode)\n",
    "    decompressor = Decompressor(trainer.decode)\n",
    "    return compressor, decompressor\n",
    "\n",
    "compressor, decompressor = make_mnist_codec(trainer)\n",
    "(originals, _), = test_DS.batch(16).skip(3).take(1)\n",
    "y, entropies = compressor(originals)\n",
    "print(\"shape(y)=\", tf.shape(y), \"max(y)=\", tf.reduce_max(y), \"entropies=\", entropies)\n",
    "reconstructed_imgs = decompressor(y)\n",
    "print(\"shape(recons)=\", tf.shape(reconstructed_imgs), \"max(recons)=\", tf.reduce_max(reconstructed_imgs))\n",
    "n = len(reconstructed_imgs)\n",
    "plt.gray()\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 )\n",
    "    plt.imshow(tf.reshape(originals[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(resize(y[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    #tf.print(reconstructed_imgs[i])\n",
    "    plt.imshow(tf.reshape(reconstructed_imgs[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(tf.shape(y))\n",
    "\n",
    "#latent = tf.constant([os.urandom(8) for _ in range(16)])\n",
    "#tf.print(latent)\n",
    "latent = tf.random.stateless_normal(shape=[16, LATENT_SPACE_LENGTH], seed=[1, 2])\n",
    "print(latent)\n",
    "#input()\n",
    "samples = decompressor(latent)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(5, 5))\n",
    "axes = axes.ravel()\n",
    "for i in range(len(axes)):\n",
    "  axes[i].imshow(tf.squeeze(samples[i]))\n",
    "  axes[i].axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6. Variational Autoencoding\n",
    "A VAE is an autoencoder that learns a latent variable model for its input data. So instead of letting the neural network learn an arbitrary function, it is learning the parameters of a probability distribution modeling the data. Now, if you sample points from this distribution, you can generate new input data samples: a VAE is a \"generative model\". See https://blog.keras.io/building-autoencoders-in-keras.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://keras.io/examples/generative/vae/ and \n",
    "# https://www.tensorflow.org/tutorials/generative/data_compression\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "EPOCHS = 1\n",
    "#EPOCHS = 30\n",
    "LAMBDA = 1.0\n",
    "\n",
    "def estimate_rate(x):\n",
    "    def entropy(row):\n",
    "        _, _, count = tf.unique_with_counts(row)\n",
    "        prob = count / tf.reduce_sum(count)\n",
    "        _2 = tf.ones_like(prob)*2\n",
    "        log_2 = tf.cast(tf.math.log(_2), tf.float64)\n",
    "        return -tf.reduce_sum(prob * tf.math.log(prob)/log_2)\n",
    "\n",
    "    value_ranges = [0.0, 32.0]\n",
    "    nbins = 256\n",
    "    print(\"estimate_rate.max(x)=\",\n",
    "          tf.reduce_max(x, axis = 1, keepdims = True),\n",
    "          \"estimate_rate.min(x)=\",\n",
    "          tf.reduce_min(x, axis = 1, keepdims = True))\n",
    "    histograms = tf.cast(tf.histogram_fixed_width_bins(x, value_ranges, nbins), tf.float32)\n",
    "    entropies = tf.map_fn(fn=entropy, elems=histograms, dtype=tf.float64)\n",
    "    rate = tf.reduce_sum(entropies)\n",
    "    \n",
    "    rate /= (tf.cast(tf.size(entropies), tf.float64))\n",
    "    return tf.cast(rate, tf.float32)\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            z_mean_entropy = estimate_rate(z_mean)\n",
    "            z_log_var_entropy = estimate_rate(z_log_var)\n",
    "            total_entropy = (z_mean_entropy + z_log_var_entropy)/2.0  # Both have the same length\n",
    "            tf.print(\"\\ntotal_entropy=\", total_entropy)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = total_entropy + LAMBDA*(reconstruction_loss + kl_loss)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x = np.concatenate([x_train, x_test], axis=0)\n",
    "x = np.expand_dims(x, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(x=x, epochs=EPOCHS, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(vae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_mean, z_log_var, z = encoder.predict(x[0:16])\n",
    "y = decoder.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y)\n",
    "plt.gray()\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1 )\n",
    "    plt.imshow(tf.reshape(x[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    #tf.print(reconstructed_imgs[i])\n",
    "    plt.imshow(tf.reshape(y[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/generative/vae/\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#EPOCHS = 5\n",
    "EPOCHS = 20\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(mnist_digits, epochs=EPOCHS, batch_size=128)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(vae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var, z = encoder.predict(x[0:16])\n",
    "y = decoder.predict(z)\n",
    "print(\"sampling (one for each encoded image):\")\n",
    "print(tf.shape(z))\n",
    "tf.print(z)\n",
    "print(\"means:\")\n",
    "print(tf.shape(z_mean))\n",
    "tf.print(z_mean)\n",
    "print(\"log variances:\")\n",
    "print(tf.shape(z_log_var))\n",
    "tf.print(z_log_var)\n",
    "n = len(y)\n",
    "plt.gray()\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1 )\n",
    "    plt.imshow(tf.reshape(x[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    #tf.print(reconstructed_imgs[i])\n",
    "    plt.imshow(tf.reshape(y[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "#from scipy.stats import entropy\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "train_DS, test_DS = tfds.load(\n",
    "    DATASET,\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=False,\n",
    ")\n",
    "\n",
    "def encode(latent_dims):\n",
    "  \"\"\"Creates the analysis (encoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2D(\n",
    "          50, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(\n",
    "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          latent_dims, use_bias=True, activation=\"relu\", name=\"latent\"),\n",
    "  ], name=\"analysis_transform\")\n",
    "\n",
    "def decode():\n",
    "  \"\"\"Creates the synthesis (decoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          2450, use_bias=True, activation=\"leaky_relu\", name=\"fc_2\"),\n",
    "      tf.keras.layers.Reshape((7, 7, 50)),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          1, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "  ], name=\"synthesis_transform\")\n",
    "\n",
    "def estimate_rate(x):\n",
    "    def entropy(row):\n",
    "        _, _, count = tf.unique_with_counts(row)\n",
    "        prob = count / tf.reduce_sum(count)\n",
    "        _2 = tf.ones_like(prob)*2\n",
    "        log_2 = tf.cast(tf.math.log(_2), tf.float64)\n",
    "        return -tf.reduce_sum(prob * tf.math.log(prob)/log_2)\n",
    "\n",
    "    value_ranges = [0.0, 32.0]\n",
    "    nbins = 256\n",
    "    print(\"estimate_rate.max(x)=\",\n",
    "          tf.reduce_max(x, axis = 1, keepdims = True),\n",
    "          \"estimate_rate.min(x)=\",\n",
    "          tf.reduce_min(x, axis = 1, keepdims = True))\n",
    "    histograms = tf.cast(tf.histogram_fixed_width_bins(x, value_ranges, nbins), tf.float32)\n",
    "    entropies = tf.map_fn(fn=entropy, elems=histograms, dtype=tf.float64)\n",
    "    rate = tf.reduce_sum(entropies)\n",
    "    \n",
    "    rate /= (tf.cast(tf.size(entropies), tf.float64))\n",
    "    return rate\n",
    "\n",
    "class Trainer(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dims):\n",
    "        super().__init__()\n",
    "        self.encode = encode(latent_dims)\n",
    "        self.decode = decode()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Computes rate and distortion losses.\"\"\"\n",
    "        # Ensure inputs are floats in the range (0, 1).\n",
    "        x = tf.cast(x, self.compute_dtype) / 255.\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))\n",
    "\n",
    "        # Compute latent space representation y, perturb it and model its entropy,\n",
    "        # then compute the reconstructed pixel-level representation x_hat.\n",
    "        y = self.encode(x)\n",
    "\n",
    "        rate = estimate_rate(y)\n",
    "        x_hat = self.decode(y)\n",
    "\n",
    "        # Average number of bits per MNIST digit.\n",
    "        rate = tf.reduce_mean(rate)\n",
    "\n",
    "        # Mean absolute difference across pixels.\n",
    "        distortion = tf.reduce_mean(abs(x - x_hat))\n",
    "\n",
    "        return dict(rate=rate, distortion=distortion)\n",
    "\n",
    "(example_batch, _), = test_DS.batch(32).take(1)\n",
    "trainer = Trainer(10)\n",
    "example_output = trainer(example_batch)\n",
    "\n",
    "print(\"rate: \", example_output[\"rate\"])\n",
    "print(\"distortion: \", example_output[\"distortion\"])\n",
    "\n",
    "def pass_through_loss(_, x):\n",
    "  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n",
    "  return x\n",
    "\n",
    "def configure_training(lmbda, latent_dims=50):\n",
    "    trainer = Trainer(latent_dims)\n",
    "    trainer.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        # Just pass through rate and distortion as losses/metrics.\n",
    "        loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "        metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "        loss_weights=dict(rate=1., distortion=lmbda),)\n",
    "    return trainer\n",
    "\n",
    "def add_rd_targets(image, label):\n",
    "    # Training is unsupervised, so labels aren't necessary here. However, we\n",
    "    # need to add \"dummy\" targets for rate and distortion.\n",
    "    processed_img = tf.reshape(image, (img_height * img_width, 1))\n",
    "    #processed_img = tf.cast(processed_img, tf.float32) / 255.\n",
    "    return processed_img, dict(rate=0., distortion=0.)\n",
    "\n",
    "def train(lmbda, epochs=5):\n",
    "    trainer = configure_training(lmbda)\n",
    "    trainer.fit(\n",
    "        train_DS.map(add_rd_targets).batch(128).prefetch(8),\n",
    "        epochs=epochs,\n",
    "        validation_data=test_DS.map(add_rd_targets).batch(128).cache(),\n",
    "        validation_freq=1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "trainer = train(lmbda=5000)\n",
    "\n",
    "class Compressor(tf.keras.Model):\n",
    "    def __init__(self, analysis_transform):\n",
    "        super().__init__()\n",
    "        self.analysis_transform = analysis_transform\n",
    "\n",
    "    def call(self, x):\n",
    "        # Ensure inputs are floats in the range (0, 1).\n",
    "        x = tf.cast(x, self.compute_dtype) / 255.\n",
    "        #x = tf.reshape(x, (-1, 28*28))\n",
    "        y = self.analysis_transform(x)\n",
    "        # Also return the exact information content of each digit.\n",
    "        rate = estimate_rate(y)\n",
    "        rate = tf.reduce_mean(rate)\n",
    "        return y, rate\n",
    "\n",
    "class Decompressor(tf.keras.Model):\n",
    "    def __init__(self, synthesis_transform):\n",
    "        super().__init__()\n",
    "        self.synthesis_transform = synthesis_transform\n",
    "\n",
    "    def call(self, y):\n",
    "        x_hat = self.synthesis_transform(y)\n",
    "        # Scale and cast back to 8-bit integer.\n",
    "        return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n",
    "\n",
    "def make_mnist_codec(trainer, **kwargs):\n",
    "    # The entropy model must be created with `compression=True` and the same\n",
    "    # instance must be shared between compressor and decompressor.\n",
    "    compressor = Compressor(trainer.encode)\n",
    "    decompressor = Decompressor(trainer.decode)\n",
    "    return compressor, decompressor\n",
    "\n",
    "compressor, decompressor = make_mnist_codec(trainer)\n",
    "(originals, _), = test_DS.batch(16).skip(3).take(1)\n",
    "y, entropies = compressor(originals)\n",
    "print(\"shape(y)=\", tf.shape(y), \"max(y)=\", tf.reduce_max(y), \"entropies=\", entropies)\n",
    "reconstructed_imgs = decompressor(y)\n",
    "print(\"shape(recons)=\", tf.shape(reconstructed_imgs), \"max(recons)=\", tf.reduce_max(reconstructed_imgs))\n",
    "n = len(reconstructed_imgs)\n",
    "plt.gray()\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 )\n",
    "    plt.imshow(tf.reshape(originals[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(resize(y[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    #tf.print(reconstructed_imgs[i])\n",
    "    plt.imshow(tf.reshape(reconstructed_imgs[i], (img_height, img_width)))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from scipy.stats import entropy\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "# Generate the NumPy arrays with the data.\n",
    "DATA_URL = f'https://storage.googleapis.com/tensorflow/tf-keras-datasets/{DATASET}.npz'\n",
    "path = tf.keras.utils.get_file(f'{DATASET}.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['x_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['x_test']\n",
    "    \n",
    "# Generate the pipelines.\n",
    "train_DS = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_DS = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Define how to use the datasets, preprocess, etc.\n",
    "\n",
    "def process_x(image, label):\n",
    "    processed_img = tf.reshape(image, (img_height * img_width, 1))\n",
    "    processed_img = tf.cast(processed_img, tf.float32) / 255.\n",
    "    return processed_img, label\n",
    "\n",
    "def process_y(image, label):\n",
    "    # The last layer of the network is a dense layer and TensorFlow imposes 1D.\n",
    "    return image, tf.reshape(image, (img_height * img_width, 1))\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_DS = train_DS.map(process_x)\n",
    "train_DS = train_DS.map(process_y)\n",
    "train_DS = train_DS.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_DS = test_DS.map(process_x)\n",
    "test_DS = test_DS.map(process_y)\n",
    "test_DS = test_DS.batch(BATCH_SIZE)\n",
    "\n",
    "class NoisyDense(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, input_dim=32, activation=\"relu\", **kwargs):\n",
    "        super(NoisyDense, self).__init__(**kwargs)\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "        self.quantized_vals = 0\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs):\n",
    "        outputs = tf.matmul(inputs, self.w) + self.b\n",
    "        #noise = tf.random.uniform(shape=tf.shape(weighted_sums), minval=-.5, maxval=.5)\n",
    "        #quantized_sums_01 = weighted_sums\n",
    "        #quantized_sums_01 = noise + weighted_sums\n",
    "        #print(tf.reduce_max(weighted_sums))\n",
    "        #outputs = tf.keras.activations.tanh(outputs)\n",
    "        outputs = tf.saturate_cast(tf.round(outputs * 255.), tf.int16)\n",
    "        #quantized_sums_8b = tf.saturate_cast(tf.round(weighted_sums * 255.), tf.int16)\n",
    "        self.quantized_vals = outputs\n",
    "        #print(len(self.quantized_vals))\n",
    "        outputs = tf.cast(outputs, tf.float32) / 255.0\n",
    "        #activations = tf.keras.activations.relu(quantized_sums_01)\n",
    "        #activations = quantized_sums_01\n",
    "        #print(len(activations))\n",
    "        #tf.print(activations)\n",
    "        #print(type(activations))\n",
    "        #print(\"act[0][0] =\",activations[0][0])\n",
    "        #print(activations.numpy())\n",
    "        #activations_entropy = entropy(tf.make_ndarray(activations), base=2)\n",
    "        #self.codestream_length = activations_entropy * tf.size(activations)\n",
    "        return outputs\n",
    "    \n",
    "    def get_vals(self):\n",
    "        return self.quantized_vals\n",
    "\n",
    "# Define the autoencoder.\n",
    "input_layer = keras.Input(\n",
    "    shape=(img_length,),\n",
    "    name=\"inputs\")\n",
    "hidden_layer = NoisyDense(\n",
    "    units=LATENT_SPACE_LENGTH,\n",
    "    input_dim = img_length,\n",
    "    activation=\"relu\",\n",
    "    name=\"hidden\"\n",
    "    )(input_layer)\n",
    "output_layer = layers.Dense(\n",
    "    img_length,\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"outputs\")(hidden_layer)\n",
    "\n",
    "autoencoder = keras.Model(\n",
    "    input_layer,\n",
    "    output_layer)\n",
    "\n",
    "# To see the latents (content of the hidden layer), we define a new \"model\" with only the encoder.\n",
    "encoder = keras.Model(\n",
    "    input_layer,\n",
    "    hidden_layer)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\", run_eagerly=True\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train.\n",
    "EPOCHS = 1\n",
    "ITERATIONS = 1\n",
    "plt.gray()\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    autoencoder.fit(\n",
    "        train_DS,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_DS)\n",
    "\n",
    "    batch_vals = autoencoder.get_layer(\"hidden\").get_vals()\n",
    "    print(\"batch_vals =\", batch_vals)\n",
    "    for j in range(BATCH_SIZE):\n",
    "        vals = batch_vals[j].numpy() + 512\n",
    "        #print(vals)\n",
    "        print(entropy(vals, base=2))\n",
    "    \n",
    "    #print(\"2\", autoencoder.get_layer(\"hidden\").variables[1])\n",
    "\n",
    "    # Show the learning.\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    n = len(train_DS)\n",
    "    if n > 32:\n",
    "        n = 32\n",
    "\n",
    "    # Show the originals (using the pipeline).\n",
    "    for images in test_DS.take(1):\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(3, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                #plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # See the latent space (as images).\n",
    "    latent_imgs = encoder.predict(test_DS)\n",
    "    print(\"type latent\", type(latent_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(resize(latent_imgs[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "        plt.axis(\"off\")    \n",
    "\n",
    "    # See the reconstructions.\n",
    "    reconstructed_imgs = autoencoder.predict(test_DS)\n",
    "    print(type(reconstructed_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.axis(\"off\")    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Quantizing only during the inference\n",
    "During the training we add uniform noise between $[-0.5, 0.5]$ to the latent space in order to simulate the distortion generated by the quantization during the generation of the predictions (see [End-to-end Optimized Image Compression](https://arxiv.org/abs/1611.01704))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from scipy.stats import entropy\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "# Generate the NumPy arrays with the data.\n",
    "DATA_URL = f'https://storage.googleapis.com/tensorflow/tf-keras-datasets/{DATASET}.npz'\n",
    "path = tf.keras.utils.get_file(f'{DATASET}.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['x_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['x_test']\n",
    "    \n",
    "# Generate the pipelines.\n",
    "train_DS = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_DS = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "# Define how to use the datasets, preprocess, etc.\n",
    "\n",
    "def process_x(image, label):\n",
    "    processed_img = tf.reshape(image, (img_height * img_width, 1))\n",
    "    processed_img = tf.cast(processed_img, tf.float32) / 255.\n",
    "    return processed_img, label\n",
    "\n",
    "def process_y(image, label):\n",
    "    # The last layer of the network is a dense layer and TensorFlow imposes 1D.\n",
    "    return image, tf.reshape(image, (img_height * img_width, 1))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_DS = train_DS.map(process_x)\n",
    "train_DS = train_DS.map(process_y)\n",
    "train_DS = train_DS.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_DS = test_DS.map(process_x)\n",
    "test_DS = test_DS.map(process_y)\n",
    "test_DS = test_DS.batch(BATCH_SIZE)\n",
    "\n",
    "class NoisyDense(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=32, input_dim=32, activation=\"relu\", **kwargs):\n",
    "        super(NoisyDense, self).__init__(**kwargs)\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "        self.quantized_vals = 0\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs):\n",
    "        outputs = tf.matmul(inputs, self.w) + self.b\n",
    "        noise = tf.random.uniform(shape=tf.shape(outputs), minval=-.5, maxval=.5)\n",
    "        #quantized_sums_01 = weighted_sums\n",
    "        outputs += noise\n",
    "        #print(tf.reduce_max(weighted_sums))\n",
    "        #outputs = tf.keras.activations.tanh(outputs)\n",
    "        #outputs = tf.saturate_cast(tf.round(outputs * 255.), tf.int16)\n",
    "        #quantized_sums_8b = tf.saturate_cast(tf.round(weighted_sums * 255.), tf.int16)\n",
    "        self.quantized_vals = outputs\n",
    "        #print(len(self.quantized_vals))\n",
    "        #outputs = tf.cast(outputs, tf.float32) / 255.0\n",
    "        #activations = tf.keras.activations.relu(quantized_sums_01)\n",
    "        #activations = quantized_sums_01\n",
    "        #print(len(activations))\n",
    "        #tf.print(activations)\n",
    "        #print(type(activations))\n",
    "        #print(\"act[0][0] =\",activations[0][0])\n",
    "        #print(activations.numpy())\n",
    "        #activations_entropy = entropy(tf.make_ndarray(activations), base=2)\n",
    "        #self.codestream_length = activations_entropy * tf.size(activations)\n",
    "        return outputs\n",
    "    \n",
    "    def get_vals(self):\n",
    "        return self.quantized_vals\n",
    "\n",
    "# Define the autoencoder.\n",
    "input_layer = keras.Input(\n",
    "    shape=(img_length,),\n",
    "    name=\"inputs\")\n",
    "hidden_layer = NoisyDense(\n",
    "    units=LATENT_SPACE_LENGTH,\n",
    "    input_dim = img_length,\n",
    "    activation=\"relu\",\n",
    "    name=\"hidden\"\n",
    "    )(input_layer)\n",
    "output_layer = layers.Dense(\n",
    "    img_length,\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"outputs\")(hidden_layer)\n",
    "\n",
    "autoencoder = keras.Model(\n",
    "    input_layer,\n",
    "    output_layer)\n",
    "\n",
    "# To see the latents (content of the hidden layer), we define a new \"model\" with only the encoder.\n",
    "encoder = keras.Model(\n",
    "    input_layer,\n",
    "    hidden_layer)\n",
    "\n",
    "autoencoder.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\", run_eagerly=True\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train.\n",
    "EPOCHS = 1\n",
    "ITERATIONS = 1\n",
    "plt.gray()\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    autoencoder.fit(\n",
    "        train_DS,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_DS)\n",
    "\n",
    "    batch_vals = autoencoder.get_layer(\"hidden\").get_vals()\n",
    "    print(\"batch_vals =\", batch_vals)\n",
    "    for j in range(BATCH_SIZE):\n",
    "        try:\n",
    "            vals = batch_vals[j].numpy() + 512\n",
    "            print(entropy(vals, base=2))\n",
    "        except:\n",
    "            pass\n",
    "        #print(vals)\n",
    "    \n",
    "    #print(\"2\", autoencoder.get_layer(\"hidden\").variables[1])\n",
    "\n",
    "    # Show the learning.\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    n = len(train_DS)\n",
    "    if n > 32:\n",
    "        n = 32\n",
    "\n",
    "    # Show the originals (using the pipeline).\n",
    "    for images in test_DS.take(1):\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(3, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                #plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # See the latent space (as images).\n",
    "    latent_imgs = encoder.predict(test_DS)\n",
    "    print(\"type latent\", type(latent_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(resize(latent_imgs[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "        plt.axis(\"off\")    \n",
    "    \n",
    "    # See the reconstructions.\n",
    "    reconstructed_imgs = autoencoder.predict(test_DS)\n",
    "    print(type(reconstructed_imgs))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.axis(\"off\")    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import tensorflow_compression as tfc\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "LATENT_LENGTH = 32\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "training_DS, test_DS = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=False,\n",
    ")\n",
    "\n",
    "# Define the autoencoder.\n",
    "def analyze(latent_length):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2D(\n",
    "          50, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(\n",
    "          img_length, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          latent_length, use_bias=True, activation=None, name=\"fc_2\"),\n",
    "  ], name=\"analysis_transform\")\n",
    "\n",
    "def synthesize():\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          2450, use_bias=True, activation=\"leaky_relu\", name=\"fc_2\"),\n",
    "      tf.keras.layers.Reshape((7, 7, 50)),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          1, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "  ], name=\"synthesis_transform\")\n",
    "\n",
    "class MNISTCompressionTrainer(tf.keras.Model):\n",
    "  \"\"\"Model that trains a compressor/decompressor for MNIST.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dims):\n",
    "    super().__init__()\n",
    "    self.analysis_transform = analyze(latent_dims)\n",
    "    self.synthesis_transform = synthesize()\n",
    "    self.prior_log_scales = tf.Variable(tf.zeros((latent_dims,)))\n",
    "\n",
    "  @property\n",
    "  def prior(self):\n",
    "    return tfc.NoisyLogistic(loc=0., scale=tf.exp(self.prior_log_scales))\n",
    "\n",
    "  def call(self, x, training):\n",
    "    \"\"\"Computes rate and distortion losses.\"\"\"\n",
    "    # Ensure inputs are floats in the range (0, 1).\n",
    "    x = tf.cast(x, self.compute_dtype) / 255.\n",
    "    x = tf.reshape(x, (-1, 28, 28, 1))\n",
    "\n",
    "    # Compute latent space representation y, perturb it and model its entropy,\n",
    "    # then compute the reconstructed pixel-level representation x_hat.\n",
    "    y = self.analysis_transform(x)\n",
    "    entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "        self.prior, coding_rank=1, compression=False)\n",
    "    y_tilde, rate = entropy_model(y, training=training)\n",
    "    x_tilde = self.synthesis_transform(y_tilde)\n",
    "\n",
    "    # Average number of bits per MNIST digit.\n",
    "    rate = tf.reduce_mean(rate)\n",
    "\n",
    "    # Mean absolute difference across pixels.\n",
    "    distortion = tf.reduce_mean(abs(x - x_tilde))\n",
    "\n",
    "    return dict(rate=rate, distortion=distortion)\n",
    "\n",
    "def pass_through_loss(_, x):\n",
    "  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n",
    "  return x\n",
    "\n",
    "def make_mnist_compression_trainer(lmbda, latent_dims=50):\n",
    "  trainer = MNISTCompressionTrainer(latent_dims)\n",
    "  trainer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    # Just pass through rate and distortion as losses/metrics.\n",
    "    loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "    metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "    loss_weights=dict(rate=1., distortion=lmbda),\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "def add_rd_targets(image, label):\n",
    "  # Training is unsupervised, so labels aren't necessary here. However, we\n",
    "  # need to add \"dummy\" targets for rate and distortion.\n",
    "  return image, dict(rate=0., distortion=0.)\n",
    "\n",
    "def train_mnist_model(lmbda):\n",
    "  trainer = make_mnist_compression_trainer(lmbda)\n",
    "  trainer.fit(\n",
    "      training_DS.map(add_rd_targets).batch(128).prefetch(8),\n",
    "      epochs=1,\n",
    "      validation_data=test_DS.map(add_rd_targets).batch(128).cache(),\n",
    "      validation_freq=1,\n",
    "      verbose=1,\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "trainer = train_mnist_model(lmbda=2000)\n",
    "trainer.summary()\n",
    "\n",
    "class MNISTCompressor(tf.keras.Model):\n",
    "  \"\"\"Compresses MNIST images to strings.\"\"\"\n",
    "\n",
    "  def __init__(self, analysis_transform, entropy_model):\n",
    "    super().__init__()\n",
    "    self.analysis_transform = analysis_transform\n",
    "    self.entropy_model = entropy_model\n",
    "\n",
    "  def call(self, x):\n",
    "    # Ensure inputs are floats in the range (0, 1).\n",
    "    x = tf.cast(x, self.compute_dtype) / 255.\n",
    "    y = self.analysis_transform(x)\n",
    "    # Also return the exact information content of each digit.\n",
    "    _, bits = self.entropy_model(y, training=False)\n",
    "    return self.entropy_model.compress(y), bits\n",
    "\n",
    "class MNISTDecompressor(tf.keras.Model):\n",
    "  \"\"\"Decompresses MNIST images from strings.\"\"\"\n",
    "\n",
    "  def __init__(self, entropy_model, synthesis_transform):\n",
    "    super().__init__()\n",
    "    self.entropy_model = entropy_model\n",
    "    self.synthesis_transform = synthesis_transform\n",
    "\n",
    "  def call(self, string):\n",
    "    y_hat = self.entropy_model.decompress(string, ())\n",
    "    x_hat = self.synthesis_transform(y_hat)\n",
    "    # Scale and cast back to 8-bit integer.\n",
    "    return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n",
    "\n",
    "def make_mnist_codec(trainer, **kwargs):\n",
    "  # The entropy model must be created with `compression=True` and the same\n",
    "  # instance must be shared between compressor and decompressor.\n",
    "  entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "      trainer.prior, coding_rank=1, compression=True, **kwargs)\n",
    "  compressor = MNISTCompressor(trainer.analysis_transform, entropy_model)\n",
    "  decompressor = MNISTDecompressor(entropy_model, trainer.synthesis_transform)\n",
    "  return compressor, decompressor\n",
    "\n",
    "compressor, decompressor = make_mnist_codec(trainer)\n",
    "\n",
    "(originals, _), = test_DS.batch(16).skip(3).take(1)\n",
    "strings, entropies = compressor(originals)\n",
    "\n",
    "print(f\"String representation of first digit in hexadecimal: 0x{strings[0].numpy().hex()}\")\n",
    "print(f\"Number of bits actually needed to represent it: {entropies[0]:0.2f}\")\n",
    "reconstructions = decompressor(strings)\n",
    "print(type(reconstructions))\n",
    "\n",
    "\n",
    "def display_digits(originals, strings, entropies, reconstructions):\n",
    "  \"\"\"Visualizes 16 digits together with their reconstructions.\"\"\"\n",
    "  fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(12.5, 5))\n",
    "  axes = axes.ravel()\n",
    "  for i in range(len(axes)):\n",
    "    image = tf.concat([\n",
    "        tf.squeeze(originals[i]),\n",
    "        tf.zeros((28, 14), tf.uint8),\n",
    "        tf.squeeze(reconstructions[i]),\n",
    "    ], 1)\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].text(\n",
    "        .5, .5, f\" 0x{strings[i].numpy().hex()} \\n{entropies[i]:0.2f} bits\",\n",
    "        ha=\"center\", va=\"top\", color=\"white\", fontsize=\"small\",\n",
    "        transform=axes[i].transAxes)\n",
    "    axes[i].axis(\"off\")\n",
    "  plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "#display_digits(originals, strings, entropies, reconstructions)\n",
    "\n",
    "#input()\n",
    "\n",
    "# Show the learning.\n",
    "plt.figure(figsize=(40,4))\n",
    "\n",
    "n = len(originals)\n",
    "if n > 32:\n",
    "    n = 32\n",
    "\n",
    "# Show the originals (using the pipeline).\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(originals[i])\n",
    "    plt.axis(\"off\")    \n",
    "\n",
    "# See the latent space (as images).\n",
    "#latent_imgs = encoder.predict(test_DS)\n",
    "#for i in range(n):\n",
    "#    ax = plt.subplot(3, n, i + 1 + n)\n",
    "#    plt.imshow(resize(latent_imgs[i],(LATENT_SPACE_LENGTH, img_width)))\n",
    "#    plt.axis(\"off\")    \n",
    "\n",
    "# See the reconstructions.\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1 + 1*n)\n",
    "    plt.imshow(reconstructions[i])\n",
    "    plt.axis(\"off\")    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_compression as tfc\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "LATENT_SPACE_LENGTH = 32\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'mnist'\n",
    "#DATASET = 'fashion_mnist'\n",
    "#URL = \"https://github.com/zalandoresearch/fashion-mnist/blob/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "img_length = img_height * img_width\n",
    "\n",
    "# Generate the NumPy arrays with the data.\n",
    "DATA_URL = f'https://storage.googleapis.com/tensorflow/tf-keras-datasets/{DATASET}.npz'\n",
    "path = tf.keras.utils.get_file(f'{DATASET}.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "    train_examples = data['x_train']\n",
    "    train_labels = data['y_train']\n",
    "    test_examples = data['x_test']\n",
    "    test_labels = data['y_test']\n",
    "\n",
    "print(type(train_examples), type(train_labels))\n",
    "print(len(train_examples), len(test_labels))\n",
    "\n",
    "# Generate the pipelines.\n",
    "train_DS = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "test_DS = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "\n",
    "print(type(train_DS))\n",
    "\n",
    "# Define how to use the datasets, preprocess, etc.\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    processed_img = tf.cast(image, tf.float32) / 255.\n",
    "    print(processed_img.shape)\n",
    "    return processed_img, label\n",
    "\n",
    "def get_image(image, label):\n",
    "    return image, tf.reshape(image, (img_height * img_width, 1))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_DS = train_DS.map(normalize_img)\n",
    "train_DS = train_DS.map(get_image)\n",
    "train_DS = train_DS.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_DS = test_DS.map(normalize_img)\n",
    "test_DS = test_DS.map(get_image)\n",
    "test_DS = test_DS.batch(BATCH_SIZE)\n",
    "\n",
    "# Define the autoencoder.\n",
    "img_pixels = img_height * img_width\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(img_height, img_width)),\n",
    "  tf.keras.layers.Dense(LATENT_SPACE_LENGTH, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train.\n",
    "EPOCHS = 1\n",
    "ITERATIONS = 5\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    model.fit(\n",
    "        train_DS,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_DS)\n",
    "\n",
    "    # Predict.\n",
    "    reconstructed_imgs = model.predict(test_DS)\n",
    "\n",
    "    # Show the predictions.\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    n = len(train_DS)\n",
    "    if n > 32:\n",
    "        n = 32\n",
    "\n",
    "    ## original\n",
    "    for images in test_DS.take(1):\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    # latent (as an image)\n",
    "    ''' \n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(resize(latents[i],(HIDDEN_SIZE, img_width)))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    '''\n",
    "\n",
    "    ## reconstruction\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.gray()\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 3 hidden layer\n",
    "\n",
    "    Input -> hidden_0 -> latent -> hidden_1 -> Output\n",
    "    28x28    10x10       32        10x10       28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoding example (feeding pipeline (tf.data.Dataset) with NumPy arrays)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Generate the NumPy arrays with the data.\n",
    "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
    "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "    train_examples = data['x_train']\n",
    "    train_labels = data['y_train']\n",
    "    test_examples = data['x_test']\n",
    "    test_labels = data['y_test']\n",
    "\n",
    "print(type(train_examples), type(train_labels))\n",
    "print(len(train_examples), len(test_labels))\n",
    "\n",
    "# Generate the pipelines.\n",
    "train_DS = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "test_DS = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "\n",
    "print(type(train_DS))\n",
    "\n",
    "# Define how to use the datasets, preprocess, etc.\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    processed_img = tf.cast(image, tf.float32) / 255.\n",
    "    print(processed_img.shape)\n",
    "    return processed_img, label\n",
    "\n",
    "def get_image(image, label):\n",
    "    return image, tf.reshape(image, (28*28, 1))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_DS = train_DS.map(normalize_img)\n",
    "train_DS = train_DS.map(get_image)\n",
    "train_DS = train_DS.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_DS = test_DS.map(normalize_img)\n",
    "test_DS = test_DS.map(get_image)\n",
    "test_DS = test_DS.batch(BATCH_SIZE)\n",
    "\n",
    "# Define the autoencoder.\n",
    "img_pixels = 28*28\n",
    "HIDDEN_SIZE = 32\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train.\n",
    "EPOCHS = 10\n",
    "model.fit(\n",
    "    train_DS,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_DS)\n",
    "\n",
    "# Predict.\n",
    "reconstructed_imgs = model.predict(test_DS)\n",
    "\n",
    "# Show the predictions.\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "plt.figure(figsize=(40,4))\n",
    "\n",
    "n = len(train_DS)\n",
    "if n > 32:\n",
    "    n = 32\n",
    "        \n",
    "## original\n",
    "for images in test_DS.take(1):\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        try:\n",
    "            image = images[0][i].numpy()\n",
    "            image *= 255\n",
    "            image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "            plt.imshow(image)\n",
    "            plt.gray()\n",
    "            plt.axis(\"off\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "## reconstruction\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "    plt.gray()\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-datasets\n",
    "#!pip install tfds-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "# Configure the size of the hidden layer.\n",
    "HIDDEN_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets (notice that we will use x_train = y_train and x_test = y_test)\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "print(x_train.shape, x_test.shape, type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gray-scale images ranges betwen [0, 255]. Neurons must work with values between [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.\n",
    "x_test = x_test.astype(\"float32\") / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = x_train[0].shape[0]\n",
    "img_width = x_train[0].shape[1]\n",
    "img_pixels = img_width*img_height\n",
    "print(\"The shape of the images is:\", img_height, \"x\", img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our layers will be 1D. The images must be reshaped.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network (2 layers), connecting them sequentially:\n",
    "# flatten(input_image, 28*28) -> hidden_layer(HIDDEN_SIZE) -> output_layer(28*28)\n",
    "input_layer = keras.Input(shape=(img_pixels,))\n",
    "hidden_layer = layers.Dense(HIDDEN_SIZE, activation=\"relu\")(input_layer)\n",
    "output_layer = layers.Dense(img_pixels, activation=\"sigmoid\")(hidden_layer)\n",
    "autoencoder = keras.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the network.\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network.\n",
    "autoencoder.fit(x=x_train, y=x_train,\n",
    "                epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the autoencoder to the test dataset.\n",
    "reconstructed_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some reconstructions.\n",
    "n = 10\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "  # original\n",
    "  ax = plt.subplot(2, n, i+1)\n",
    "  plt.imshow(x_test[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  \n",
    "  # reconstruction\n",
    "  ax = plt.subplot(2, n, i+1+n)\n",
    "  plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the latents (content of the hidden layer), we define a new \"model\" with only the encoder.\n",
    "encoder = keras.Model(input_layer, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "n = 10\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "  # original\n",
    "  ax = plt.subplot(2, n, i+1)\n",
    "  plt.imshow(x_test[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  \n",
    "  # latent (as an image)\n",
    "  ax = plt.subplot(2, n, i+1+n)\n",
    "  plt.imshow(resize(latents[i],(HIDDEN_SIZE, img_width)))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images of any shape and the training dataset does not fit in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-datasets\n",
    "#!pip install tfds-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1coyad69BMc"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available datasets in TensorFlow.\n",
    "#tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64 # -1 -> All the dataset in memory!\n",
    "\n",
    "# https://www.tensorflow.org/datasets/catalog/\n",
    "DATASET = 'clic'  # 7.48 GiB :-()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DS = tfds.load(\n",
    "    name=DATASET,\n",
    "    split='train',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_files=True) # During training, it's important to shuffle the data well - poorly shuffled data can result in lower training accuracy (https://www.tensorflow.org/datasets/performances).\n",
    "\n",
    "test_DS = tfds.load(\n",
    "    name=DATASET,\n",
    "    split=\"test\",\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering example\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "print(ds_train, len(ds_train))\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  #print(image)\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(32)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "print(ds_train, len(ds_train))\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(32)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(28*28)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")\n",
    "\n",
    "reconstructed_imgs = model.predict(ds_test)\n",
    "# Show some reconstructions.\n",
    "n = 10\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "  # original\n",
    "  ax = plt.subplot(2, n, i+1)\n",
    "  #plt.imshow(np.squeeze(ds_test)[i].reshape(img_height, img_width))\n",
    "  plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  \n",
    "  # reconstruction\n",
    "  ax = plt.subplot(2, n, i+1+n)\n",
    "  plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Autoencoding example (using a data pipeline)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True, # Images are labeled\n",
    "    with_info=True\n",
    ")\n",
    "print(ds_train, len(ds_train))\n",
    "\n",
    "def normalize_img2(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    #print(image['image'].shape)\n",
    "    #print(image)\n",
    "    #return image, label\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def get_image(image, label):\n",
    "    return image, tf.reshape(image, (28*28, 1))\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img2, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.map(get_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(32)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "#ds_train = ds_train.map(lambda x: x[0])\n",
    "\n",
    "print(ds_train, len(ds_train))\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(get_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(32)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "#ds_test = ds_test.map(lambda x: x[0], ds_test)\n",
    "\n",
    "print(ds_test, len(ds_test))\n",
    "\n",
    "#x_test = list(map(lambda x: x[0], ds_test))\n",
    "# = ds_test[\"image\"]\n",
    "\n",
    "img_pixels = 28*28\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=ds_test)\n",
    "\n",
    "reconstructed_imgs = model.predict(ds_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(40,4))\n",
    "\n",
    "# original\n",
    "for images in ds_test.take(1):\n",
    "    print(len(images))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        image = images[0][i].numpy()\n",
    "        image *= 255\n",
    "        image = image.astype(\"uint8\").reshape(28, 28)\n",
    "        plt.imshow(image)\n",
    "        plt.gray()\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "# reconstruction\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Autoencoding example (iterative)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_pixels = 28*28\n",
    "HIDDEN_SIZE = 32\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  #print(image)\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def get_image(image, label):\n",
    "    return image, tf.reshape(image, (28*28, 1))\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "ITERATIONS = 20\n",
    "for i in range(ITERATIONS):\n",
    "    \n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'mnist',\n",
    "        split=['train', 'test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True, # Images are labeled\n",
    "        with_info=True)\n",
    "    \n",
    "    ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.map(get_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(\n",
    "        ds_info.splits['train'].num_examples,\n",
    "        reshuffle_each_iteration=True)\n",
    "    ds_train = ds_train.batch(32)\n",
    "    ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.map(get_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.batch(32)\n",
    "    ds_test = ds_test.cache()\n",
    "    #ds_test = ds_test.shuffle(ds_info.splits['test[:10%]'].num_examples,\n",
    "    #    reshuffle_each_iteration=True)\n",
    "    ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    print(\"len(train_DS) =\", len(ds_train))\n",
    "    print(\"len(test_DS) =\", len(ds_test))\n",
    "    \n",
    "    n = len(ds_train)\n",
    "    if n > 10:\n",
    "        n = 10\n",
    "    for images in ds_train.take(1):\n",
    "        print(len(images))\n",
    "        for i in range(min(len(ds_train), n)):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    EPOCHS = 1\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=ds_test)\n",
    "\n",
    "    reconstructed_imgs = model.predict(ds_test)\n",
    "\n",
    "    plt.figure(figsize=(40,4))\n",
    "    #plt.figure()\n",
    "\n",
    "    # original\n",
    "    for images in ds_test.take(1):\n",
    "        #print(len(images))\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # reconstruction\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.gray()\n",
    "        #ax.get_xaxis().set_visible(False)\n",
    "        #ax.get_yaxis().set_visible(False)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Autoencoding example (iterative, minimal)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_pixels = 28*28\n",
    "HIDDEN_SIZE = 32\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  #print(image)\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def get_image(image, label):\n",
    "    return image, tf.reshape(image, (28*28, 1))\n",
    "    \n",
    "img_width = 28\n",
    "img_height = 28\n",
    "ITERATIONS = 20\n",
    "for i in range(ITERATIONS):\n",
    "    \n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'mnist',\n",
    "        split=['train[:1000]', 'test'],\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True, # Images are labeled\n",
    "        with_info=True)\n",
    "    \n",
    "    ds_train = ds_train.map(normalize_img)\n",
    "    ds_train = ds_train.map(get_image)\n",
    "    ds_train = ds_train.cache() # Do not put me in the last position\n",
    "    ds_train = ds_train.shuffle(\n",
    "        ds_info.splits['train'].num_examples,\n",
    "        reshuffle_each_iteration=True)\n",
    "    ds_train = ds_train.batch(32)\n",
    "\n",
    "    ds_test = ds_test.map(normalize_img)\n",
    "    ds_test = ds_test.map(get_image)\n",
    "    ds_test = ds_test.shuffle(\n",
    "        ds_info.splits['test'].num_examples,\n",
    "        reshuffle_each_iteration=True)\n",
    "    ds_test = ds_test.batch(32)\n",
    "    ds_test = ds_test.cache() # Put me in the last position\n",
    "\n",
    "    print(\"len(train_DS) =\", len(ds_train))\n",
    "    print(\"len(test_DS) =\", len(ds_test))\n",
    "    \n",
    "    n = len(ds_train)\n",
    "    if n > 32:\n",
    "        n = 32\n",
    "        \n",
    "    plt.figure(figsize=(40,2))\n",
    "    \n",
    "    for images in ds_train.take(1):\n",
    "        print(len(images))\n",
    "        for i in range(min(len(ds_train), n)):\n",
    "            ax = plt.subplot(1, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    EPOCHS = 1\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=ds_test)\n",
    "\n",
    "    reconstructed_imgs = model.predict(ds_test)\n",
    "\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    # original\n",
    "    for images in ds_test.take(1):\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # reconstruction\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.gray()\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoding example (iterative, minimal, clic) FREEZES :-(\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_pixels = 28*28\n",
    "HIDDEN_SIZE = 32\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def normalize_img(image):\n",
    "    #print(type(image['image']))\n",
    "    processed_img = tf.cast(image['image'], tf.float32) / 255.\n",
    "    #print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    processed_img = tf.image.resize(processed_img, [28, 28])\n",
    "    if processed_img.get_shape().as_list()[2] > 1:\n",
    "        processed_img = tf.image.rgb_to_grayscale(processed_img) \n",
    "    #print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    return processed_img\n",
    "\n",
    "def get_image(image):\n",
    "    return image, tf.reshape(image, (28*28, 1))\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "ITERATIONS = 20\n",
    "for i in range(ITERATIONS):\n",
    "    \n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'clic',\n",
    "        split=['train[:32]', 'test[:32]'],\n",
    "        shuffle_files=True,\n",
    "        #as_supervised=True, # Images are labeled\n",
    "        with_info=True)\n",
    "    \n",
    "    ds_train = ds_train.map(normalize_img)\n",
    "    ds_train = ds_train.map(get_image)\n",
    "    ds_train = ds_train.cache() # Do not put me in the last position\n",
    "    ds_train = ds_train.shuffle(\n",
    "        ds_info.splits['train'].num_examples,\n",
    "        reshuffle_each_iteration=True)\n",
    "    ds_train = ds_train.batch(32)\n",
    "\n",
    "    ds_test = ds_test.map(normalize_img)\n",
    "    ds_test = ds_test.map(get_image)\n",
    "    ds_test = ds_test.shuffle(\n",
    "        ds_info.splits['test'].num_examples,\n",
    "        reshuffle_each_iteration=True)\n",
    "    ds_test = ds_test.batch(32)\n",
    "    ds_test = ds_test.cache() # Put me in the last position\n",
    "\n",
    "    print(\"len(train_DS) =\", len(ds_train))\n",
    "    print(\"len(test_DS) =\", len(ds_test))\n",
    "    \n",
    "    n = len(ds_train)\n",
    "    if n > 32:\n",
    "        n = 32\n",
    "        \n",
    "    plt.figure(figsize=(40,2))\n",
    "    \n",
    "    for images in ds_train.take(1):\n",
    "        print(len(images))\n",
    "        for i in range(min(len(ds_train), n)):\n",
    "            ax = plt.subplot(1, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    EPOCHS = 1\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=ds_test)\n",
    "\n",
    "    reconstructed_imgs = model.predict(ds_test)\n",
    "\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    # original\n",
    "    for images in ds_test.take(1):\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            try:\n",
    "                image = images[0][i].numpy()\n",
    "                image *= 255\n",
    "                image = image.astype(\"uint8\").reshape(img_height, img_width)\n",
    "                plt.imshow(image)\n",
    "                plt.gray()\n",
    "                plt.axis(\"off\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # reconstruction\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "        plt.gray()\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using clic images (freezes)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "img_pixels = 64*64\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(64, 64)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def process_dataset(image):\n",
    "    #print(type(image['image']))\n",
    "    processed_img = tf.cast(image['image'], tf.float32) / 255.\n",
    "    #print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    processed_img = tf.image.resize(processed_img, [64, 64])\n",
    "    if processed_img.get_shape().as_list()[2] > 1:\n",
    "        processed_img = tf.image.rgb_to_grayscale(processed_img) \n",
    "    #print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    return processed_img\n",
    "\n",
    "def define_y(image):\n",
    "    return image, tf.reshape(image, (64*64, 1))\n",
    "\n",
    "EPOCHS = 1\n",
    "ITERATIONS = 100\n",
    "for i in range(ITERATIONS):\n",
    "    print(\"iteration\", i)\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'clic',\n",
    "        split=['train[:128]', 'test[:16]'],\n",
    "        shuffle_files=True, # Shuffle the files between each epoch.\n",
    "        with_info=True)\n",
    "\n",
    "    ds_train = ds_train.map(process_dataset)\n",
    "    #ds_train = ds_train.map(process_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.map(define_y)\n",
    "    #ds_train = ds_train.map(define_y, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    #ds_train = ds_train.cache()\n",
    "    #ds_train = ds_train.shuffle(\n",
    "    #    ds_info.splits['train'].num_examples,\n",
    "    #    reshuffle_each_iteration=True)\n",
    "    ds_train = ds_train.batch(32)\n",
    "    #ds_train = ds_train.batch(32, drop_remainder=True)\n",
    "    #ds_train = ds_train.batch(1024, drop_remainder=True)\n",
    "    #ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds_test = ds_test.map(process_dataset)\n",
    "    #ds_test = ds_test.map(process_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.map(define_y)\n",
    "    #ds_test = ds_test.map(define_y, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.batch(32)\n",
    "    #ds_test = ds_test.batch(1024, drop_remainder=True)\n",
    "    #ds_test = ds_test.cache()\n",
    "    #ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        epochs=EPOCHS,#//10#,\n",
    "        #shuffle='batch',\n",
    "        #verbose=2,\n",
    "        validation_data=ds_test\n",
    "    )\n",
    "    #model.save(\"model\")\n",
    "    #model.load(\"model\")\n",
    "    \n",
    "    reconstructed_imgs = model.predict(ds_test)\n",
    "\n",
    "    n = 10\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    # original\n",
    "    for images in ds_test.take(1):\n",
    "        print(len(images))\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            image = images[0][i].numpy()\n",
    "            image *= 255\n",
    "            image = image.astype(\"uint8\").reshape(64, 64)\n",
    "            plt.imshow(image)\n",
    "            plt.gray()\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    # reconstruction\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(reconstructed_imgs[i].reshape(64, 64))\n",
    "      plt.gray()\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using clic images (save and load)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "img_pixels = 64*64\n",
    "\n",
    "#input_layer = keras.Input(shape=(64*64,))\n",
    "#hidden_layer = layers.Dense(HIDDEN_SIZE, activation=\"relu\")(input_layer)\n",
    "#output_layer = layers.Dense(img_pixels, activation=\"sigmoid\")(hidden_layer)\n",
    "#model = keras.Model(input_layer, output_layer)\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(64, 64)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def process_dataset(image):\n",
    "    #print(type(image['image']))\n",
    "    processed_img = tf.cast(image['image'], tf.float32) / 255.\n",
    "    #print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    processed_img = tf.image.resize(processed_img, [64, 64])\n",
    "    if processed_img.get_shape().as_list()[2] > 1:\n",
    "        processed_img = tf.image.rgb_to_grayscale(processed_img)\n",
    "    #print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    #processed_img = tf.image.resize(processed_img, [64*64, 1])\n",
    "    return processed_img\n",
    "\n",
    "def define_y(image):\n",
    "    return image, tf.reshape(image, (64*64, 1))\n",
    "\n",
    "EPOCHS = 1\n",
    "ITERATIONS = 100\n",
    "for i in range(ITERATIONS):\n",
    "    print(\"iteration\", i)\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'clic',\n",
    "        split=['train[:128]', 'test[:16]'],\n",
    "        shuffle_files=True, # Shuffle the files between each epoch.\n",
    "        with_info=True)\n",
    "\n",
    "    ds_train = ds_train.map(process_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.map(define_y, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(\n",
    "        ds_info.splits['train'].num_examples,\n",
    "        reshuffle_each_iteration=True)\n",
    "    ds_train = ds_train.batch(32)\n",
    "    #ds_train = ds_train.batch(1024, drop_remainder=True)\n",
    "    ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds_test = ds_test.map(process_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.map(define_y, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.batch(32)\n",
    "    #ds_test = ds_test.batch(1024, drop_remainder=True)\n",
    "    ds_test = ds_test.cache()\n",
    "    ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    model.fit(\n",
    "        ds_train,\n",
    "        epochs=EPOCHS,#//10#,\n",
    "        #shuffle='batch',\n",
    "        validation_data=ds_test\n",
    "    )\n",
    "    keras.models.save_model(model, \"model\")\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(64, 64)),\n",
    "      tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "      tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=\"binary_crossentropy\"\n",
    "    )\n",
    "\n",
    "    model = keras.models.load_model(\"model\")\n",
    "\n",
    "    #model.load(\"model\")\n",
    "    \n",
    "    reconstructed_imgs = model.predict(ds_test)\n",
    "\n",
    "    n = 10\n",
    "    plt.figure(figsize=(40,4))\n",
    "\n",
    "    # original\n",
    "    for images in ds_test.take(1):\n",
    "        print(len(images))\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            image = images[0][i].numpy()\n",
    "            image *= 255\n",
    "            image = image.astype(\"uint8\").reshape(64, 64)\n",
    "            plt.imshow(image)\n",
    "            plt.gray()\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    # reconstruction\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(reconstructed_imgs[i].reshape(64, 64))\n",
    "      plt.gray()\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using clic images (using a custom callback to visualize the training dataset after each epoch)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils import Sequence\n",
    "from skimage.io import imread\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "img_pixels = 64*64\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(64, 64)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "def process_dataset(image):\n",
    "    #print(type(image['image']))\n",
    "    processed_img = tf.cast(image['image'], tf.float32) / 255.\n",
    "    #print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    processed_img = tf.image.resize(processed_img, [64, 64])\n",
    "    if processed_img.get_shape().as_list()[2] > 1:\n",
    "        processed_img = tf.image.rgb_to_grayscale(processed_img) \n",
    "    #print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    return processed_img\n",
    "\n",
    "def define_y(image):\n",
    "    return image, tf.reshape(image, (64*64, 1))\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "def load_data():\n",
    "    (ds_train, ds_test), ds_info = tfds.load(\n",
    "        'clic',\n",
    "        split=['train[:10]', 'test[:10]'],\n",
    "        shuffle_files=True, # Shuffle the files between each epoch.\n",
    "        with_info=True)\n",
    "\n",
    "    ds_train = ds_train.map(process_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.map(define_y, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(\n",
    "        ds_info.splits['train'].num_examples,\n",
    "        reshuffle_each_iteration=True)\n",
    "    ds_train = ds_train.batch(10)\n",
    "    #ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    n = 10\n",
    "    for images in ds_train.take(1):\n",
    "        print(len(images))\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            image = images[0][i].numpy()\n",
    "            image *= 255\n",
    "            image = image.astype(\"uint8\").reshape(64, 64)\n",
    "            plt.imshow(image)\n",
    "            plt.gray()\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    ds_test = ds_test.map(process_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.map(define_y, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_test = ds_test.batch(10)\n",
    "    ds_test = ds_test.cache()\n",
    "    #ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds_train, ds_test\n",
    "    \n",
    "ds_train, ds_test = load_data()\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        load_data()\n",
    "        keys = list(logs.keys())\n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=EPOCHS,#//10#,\n",
    "    shuffle='batch',\n",
    "    validation_data=ds_test,\n",
    "    callbacks=[CustomCallback()]\n",
    ")\n",
    "\n",
    "reconstructed_imgs = model.predict(ds_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(40,4))\n",
    "\n",
    "# original\n",
    "for images in ds_test.take(1):\n",
    "    print(len(images))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        image = images[0][i].numpy()\n",
    "        image *= 255\n",
    "        image = image.astype(\"uint8\").reshape(64, 64)\n",
    "        plt.imshow(image)\n",
    "        plt.gray()\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "# reconstruction\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.imshow(reconstructed_imgs[i].reshape(64, 64))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tf.__version__)\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'clic',\n",
    "    split=['train[:4%]', 'test[:1%]'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True\n",
    ")\n",
    "print(ds_train, len(ds_train))\n",
    "\n",
    "def process_dataset(image):\n",
    "    print(type(image['image']))\n",
    "    processed_img = tf.cast(image['image'], tf.float32) / 255.\n",
    "    print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    processed_img = tf.image.resize(processed_img, [64, 64])\n",
    "    if processed_img.get_shape().as_list()[2] > 1:\n",
    "        processed_img = tf.image.rgb_to_grayscale(processed_img) \n",
    "    print(processed_img.get_shape().as_list(), processed_img.dtype)\n",
    "    return processed_img\n",
    "\n",
    "def define_y(image):\n",
    "    return image, tf.reshape(image, (64*64, 1))\n",
    "\n",
    "#ds_train = ds_train.map(get_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.map(process_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.map(define_y, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(1024)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "#class_names = ds_train.class_names\n",
    "\n",
    "print(\"take=\", ds_train.take(1))\n",
    "\n",
    "for images in ds_train.take(1):\n",
    "    print(len(images))\n",
    "    for i in range(32):\n",
    "        #print(len(images[i]))\n",
    "        ax = plt.subplot(6, 6, i + 1)\n",
    "        # plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        image = images[0][i].numpy()\n",
    "        image *= 255\n",
    "        image = image.astype(\"uint8\").reshape(64,64)\n",
    "        #print(image.shape)\n",
    "        plt.imshow(image)\n",
    "        plt.gray()\n",
    "        #plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_train, len(ds_train))\n",
    "\n",
    "ds_test = ds_test.map(process_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(define_y, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(1024)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(ds_test, len(ds_test))\n",
    "\n",
    "img_pixels = 64*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 256\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(64, 64)),\n",
    "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dense(img_pixels, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_imgs = model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reconstructed_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reconstructed_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some reconstructions.\n",
    "n = 4\n",
    "\n",
    "img_width = 64\n",
    "img_height = 64\n",
    "\n",
    "for images in ds_train.take(1):\n",
    "    print(len(images))\n",
    "    for i in range(32):\n",
    "        #print(len(images[i]))\n",
    "        ax = plt.subplot(6, 6, i + 1)\n",
    "        # plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        image = images[0][i].numpy()\n",
    "        image *= 255\n",
    "        image = image.astype(\"uint8\").reshape(64,64)\n",
    "        #print(image.shape)\n",
    "        plt.imshow(image)\n",
    "        #plt.title(class_names[labels[i]])\n",
    "        plt.gray()\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "for i in range(n):\n",
    "  # reconstruction\n",
    "  ax = plt.subplot(2, n, i+1+n)\n",
    "  plt.imshow(reconstructed_imgs[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))> 60000\n",
    "<PrefetchDataset element_spec={'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None)}> 163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64*64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
    "    \n",
    "<PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
    "    \n",
    "<PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(train_DS, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "train_DS = train_DS.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
    "class CLIC_Sequence(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)#.astype(np.int)\n",
    "    \n",
    "    def get_batch(batch_filenames):\n",
    "        batch = []\n",
    "        for filename in batch_filenames:\n",
    "            image = imread(filename)\n",
    "            resized_image = resize(image, (200, 200))\n",
    "            image_01 = resized_image / 255.0\n",
    "            batch.append(image_01)\n",
    "        return batch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        image = imread(file_name)\n",
    "        resized_image = resize(image, (200, 200))\n",
    "        return np.array(get_batch(batch_x)), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_DS = tfds.as_numpy(train_DS) \n",
    "test_DS = tfds.as_numpy(test_DS)\n",
    "\n",
    "x_train, y_train = train_DS[\"image\"], train_DS[\"label\"]\n",
    "x_test, y_test = test_DS[\"image\"], test_DS[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AM4fXOK9cJw"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.\n",
    "x_test = x_test.astype(\"float32\") / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTUNAdp0DHKw",
    "outputId": "01017f1a-9120-469b-d6f8-f0fcd2488fa5"
   },
   "outputs": [],
   "source": [
    "encoding_dim = 32\n",
    "img_height = x_train[0].shape[0]\n",
    "img_width = x_train[0].shape[1]\n",
    "img_pixels = img_width*img_height\n",
    "print(img_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0gCxpWE9oRO"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K45AxjIt9ybm",
    "outputId": "fd46a747-6035-4f9c-f1c9-ef03a1e6f52b"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVUVpQbK9_b8"
   },
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(img_pixels,))\n",
    "encoded = layers.Dense(encoding_dim, activation=\"relu\")(input_img)\n",
    "decoded = layers.Dense(img_pixels, activation=\"sigmoid\")(encoded)\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuSPjQfJ-r8x"
   },
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bh4GmiMe-4eq"
   },
   "outputs": [],
   "source": [
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEJOgaf5_B4w"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDrJL3Vf_X6C",
    "outputId": "fb6488b1-bc2d-4118-b5b4-526944b72ff9"
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hH5j883j_kIO"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHSwhvZzAmFJ"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "1oNhxQWfApwg",
    "outputId": "895cb67b-cb4e-4105-ff7f-1869ab0413ba"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(40,4))\n",
    "for i in range(n):\n",
    "  # original\n",
    "  ax = plt.subplot(2, n, i+1)\n",
    "  plt.imshow(x_test[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  \n",
    "  # reconstruction\n",
    "  ax = plt.subplot(2, n, i+1+n)\n",
    "  plt.imshow(decoded_imgs[i].reshape(img_height, img_width))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNbUYPExBiSL"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_img(img, label):\n",
    "  img = tf.cast(img, tf.float32) / 255.\n",
    "  return (img, label)\n",
    "\n",
    "train_DS = tfds.load('mnist', split='train', as_supervised=True)\n",
    "train_DS = train_DS.batch(32)\n",
    "train_DS = train_DS.map(_normalize_img)\n",
    "\n",
    "test_DS = tfds.load('mnist', split='test', as_supervised=True)\n",
    "test_DS = test_DS.batch(32)\n",
    "test_DS = test_DS.map(_normalize_img)\n",
    "\n",
    "#model.fit(ds_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_img(img, label):\n",
    "  img = tf.cast(img, tf.float32) / 255.\n",
    "  return (img, label)\n",
    "\n",
    "train_DS = tfds.load('mnist', split='train', as_supervised=True)\n",
    "train_DS = train_DS.batch(32)\n",
    "train_DS = train_DS.map(_normalize_img)\n",
    "\n",
    "test_DS = tfds.load('mnist', split='test', as_supervised=True)\n",
    "test_DS = test_DS.batch(32)\n",
    "test_DS = test_DS.map(_normalize_img)\n",
    "\n",
    "#model.fit(ds_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_DS, test_DS), info = tfds.load(name=\"mnist\", split=[tfds.Split.TRAIN,tfds.Split.TEST], with_info=True, as_supervised=True)\n",
    "train_size = info.splits['train'].num_examples\n",
    "test_size = info.splits['test'].num_examples\n",
    "print(train_size, test_size)\n",
    "\n",
    "def _normalize_img(img, label):\n",
    "  img = tf.cast(img, tf.float32) / 255.\n",
    "  return (img, label)\n",
    "\n",
    "train_DS = train_DS.batch(32)\n",
    "train_DS = train_DS.map(_normalize_img)\n",
    "test_DS = test_DS.batch(32)\n",
    "test_DS = test_DS.map(_normalize_img)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "one_layer_AE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
